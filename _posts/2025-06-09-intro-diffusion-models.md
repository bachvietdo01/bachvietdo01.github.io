---
layout: post
title: "A Gentle Intro to Diffusion Models"
author: "Bach Do"
categories: journal
tags: [documentation,sample]
image: a2_diffusion_model_logo.gif
---

Diffusion models have recently emerged as a powerful class of deep generative models, achieving state-of-the-art results in image generation, audio synthesis, protein design, and many scientific domains. Notable works in the literature include [Sohl-Dickstein et al. (2015)](https://arxiv.org/abs/1503.03585), [Ho et al. (2020)](https://arxiv.org/abs/2006.11239), [Song, Ermon et al. (2019)](https://arxiv.org/abs/1907.05600), [Song, Sohl-Dickstein et al. (2020)](https://arxiv.org/abs/2011.13456), and [Karras et al. (2022)](https://arxiv.org/abs/2206.00364). This introduction explains the core idea of diffusion models as flows generated by a Stochastic Differential Equation (SDE) and walks through a full example of how to sample an 11-component Gaussian mixture data starting from a standard normal initial distribution. The full codes can be found [here](https://github.com/bachvietdo01/generative_models/tree/main/diffusion_model).


## Stochastic Flows by SDE

A common view of diffusion models is learning to reverse a forward process that progressively diffuse data into noise. However, they can also be seen as a stochastic counterpart to flow matching models (see Holderrieth et al., 2025). [Flow matching](https://bachvietdo01.github.io/intro-to-flow-matching-models) describes flows generated by an ODE: $\frac{dX_t}{dt} = u_t(X_t)$. In contrast, diffusion models are stochastic flows, solutions to the Stochastic Differential Equation:

$$
\begin{aligned}
dX_t = u_t(X_t)dt + \frac{\sigma_t^2}{2} \log \nabla \log p_t(X_t) dt + \sigma_t d W_t \quad (1)
\end{aligned}
$$

Here, $X_t \sim p_t(\cdot)$ traces the marginal probability path, $u_t(X_t)$ is the deterministic vector field, $\sigma_t^2$ is the diffusion coefficient, and $W_t$ denotes Brownian motion. Personally, I find the SDE perspective more intuitive and rigorous.

<p align="center">
<img src="https://github.com/bachvietdo01/bachvietdo01.github.io/blob/main/assets/img/a2_ode_traj.png?raw=true" alt="ode_traj" width="450"/>
<img src="https://github.com/bachvietdo01/bachvietdo01.github.io/blob/main/assets/img/a2_sde_traj.png?raw=true" alt="sde_traj" width="450"/> 
</p>

The SDE $(1)$ implies that for sufficiently small $h > 0$, $X_{t+h} = X_t + h\cdot u_t + h \cdot \frac{\sigma_t^2}{2} \nabla \log p_t(X_t) + \sqrt{h} \cdot N(\cdot | 0, I)$.

## Construct Conditional and Marginal Probability Path

As in Flow Matching setup, given a data sample $z_1, z_2, \ldots, z_n$, we first construct a conditional probability path $p_0(\cdot \mid z), \ldots, p_t(\cdot \mid z), \ldots, p_1(\cdot \mid z)$. A common choice in the literature is Conditional Gassian path $p_t(\cdot | z) = N(\cdot \mid \alpha_t z  ,  \beta_t^2 I)$ where $\alpha_t$ and $\beta_t$ are noise schedulers and $\alpha_t \to 1$ and $\beta_t^2 \to 0$ as $t \to 1$.

## Reference

[1] Lipman, Y., Chen, R. T., Ben-Hamu, H., Nickel, M., & Le, M. (2022). Flow matching for generative modeling. arXiv preprint arXiv:2210.02747.

[2] Holderrieth, Peter, and Ezra Erives. "An Introduction to Flow Matching and Diffusion Models." arXiv preprint arXiv:2506.02070 (2025).




